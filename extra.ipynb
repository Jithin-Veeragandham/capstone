{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jithi\\OneDrive\\Desktop\\VsCode\\capstone\\extra.ipynb Cell 1\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jithi/OneDrive/Desktop/VsCode/capstone/extra.ipynb#W0sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mopenai\u001b[39;00m \u001b[39mimport\u001b[39;00m OpenAI\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jithi/OneDrive/Desktop/VsCode/capstone/extra.ipynb#W0sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m client \u001b[39m=\u001b[39m OpenAI()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jithi/OneDrive/Desktop/VsCode/capstone/extra.ipynb#W0sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m response \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39;49mchat\u001b[39m.\u001b[39;49mcompletions\u001b[39m.\u001b[39;49mcreate(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jithi/OneDrive/Desktop/VsCode/capstone/extra.ipynb#W0sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m   model\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mgpt-3.5-turbo\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jithi/OneDrive/Desktop/VsCode/capstone/extra.ipynb#W0sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m   messages\u001b[39m=\u001b[39;49m[\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jithi/OneDrive/Desktop/VsCode/capstone/extra.ipynb#W0sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     {\u001b[39m\"\u001b[39;49m\u001b[39mrole\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39msystem\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcontent\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39mYou are a helpful assistant.\u001b[39;49m\u001b[39m\"\u001b[39;49m}\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jithi/OneDrive/Desktop/VsCode/capstone/extra.ipynb#W0sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jithi/OneDrive/Desktop/VsCode/capstone/extra.ipynb#W0sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m   ]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jithi/OneDrive/Desktop/VsCode/capstone/extra.ipynb#W0sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\jithi\\.conda\\envs\\pytorch_OIIO\\lib\\site-packages\\openai\\_utils\\_utils.py:299\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    297\u001b[0m             msg \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMissing required argument: \u001b[39m\u001b[39m{\u001b[39;00mquote(missing[\u001b[39m0\u001b[39m])\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    298\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 299\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jithi\\.conda\\envs\\pytorch_OIIO\\lib\\site-packages\\openai\\resources\\chat\\completions.py:598\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, max_tokens, n, presence_penalty, response_format, seed, stop, stream, temperature, tool_choice, tools, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    551\u001b[0m \u001b[39m@required_args\u001b[39m([\u001b[39m\"\u001b[39m\u001b[39mmessages\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m], [\u001b[39m\"\u001b[39m\u001b[39mmessages\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mstream\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m    552\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[0;32m    553\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    596\u001b[0m     timeout: \u001b[39mfloat\u001b[39m \u001b[39m|\u001b[39m httpx\u001b[39m.\u001b[39mTimeout \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m|\u001b[39m NotGiven \u001b[39m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m    597\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ChatCompletion \u001b[39m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m--> 598\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_post(\n\u001b[0;32m    599\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39m/chat/completions\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    600\u001b[0m         body\u001b[39m=\u001b[39;49mmaybe_transform(\n\u001b[0;32m    601\u001b[0m             {\n\u001b[0;32m    602\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mmessages\u001b[39;49m\u001b[39m\"\u001b[39;49m: messages,\n\u001b[0;32m    603\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mmodel\u001b[39;49m\u001b[39m\"\u001b[39;49m: model,\n\u001b[0;32m    604\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mfrequency_penalty\u001b[39;49m\u001b[39m\"\u001b[39;49m: frequency_penalty,\n\u001b[0;32m    605\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mfunction_call\u001b[39;49m\u001b[39m\"\u001b[39;49m: function_call,\n\u001b[0;32m    606\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mfunctions\u001b[39;49m\u001b[39m\"\u001b[39;49m: functions,\n\u001b[0;32m    607\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mlogit_bias\u001b[39;49m\u001b[39m\"\u001b[39;49m: logit_bias,\n\u001b[0;32m    608\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mmax_tokens\u001b[39;49m\u001b[39m\"\u001b[39;49m: max_tokens,\n\u001b[0;32m    609\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mn\u001b[39;49m\u001b[39m\"\u001b[39;49m: n,\n\u001b[0;32m    610\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mpresence_penalty\u001b[39;49m\u001b[39m\"\u001b[39;49m: presence_penalty,\n\u001b[0;32m    611\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mresponse_format\u001b[39;49m\u001b[39m\"\u001b[39;49m: response_format,\n\u001b[0;32m    612\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mseed\u001b[39;49m\u001b[39m\"\u001b[39;49m: seed,\n\u001b[0;32m    613\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mstop\u001b[39;49m\u001b[39m\"\u001b[39;49m: stop,\n\u001b[0;32m    614\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mstream\u001b[39;49m\u001b[39m\"\u001b[39;49m: stream,\n\u001b[0;32m    615\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtemperature\u001b[39;49m\u001b[39m\"\u001b[39;49m: temperature,\n\u001b[0;32m    616\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtool_choice\u001b[39;49m\u001b[39m\"\u001b[39;49m: tool_choice,\n\u001b[0;32m    617\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtools\u001b[39;49m\u001b[39m\"\u001b[39;49m: tools,\n\u001b[0;32m    618\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtop_p\u001b[39;49m\u001b[39m\"\u001b[39;49m: top_p,\n\u001b[0;32m    619\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39muser\u001b[39;49m\u001b[39m\"\u001b[39;49m: user,\n\u001b[0;32m    620\u001b[0m             },\n\u001b[0;32m    621\u001b[0m             completion_create_params\u001b[39m.\u001b[39;49mCompletionCreateParams,\n\u001b[0;32m    622\u001b[0m         ),\n\u001b[0;32m    623\u001b[0m         options\u001b[39m=\u001b[39;49mmake_request_options(\n\u001b[0;32m    624\u001b[0m             extra_headers\u001b[39m=\u001b[39;49mextra_headers, extra_query\u001b[39m=\u001b[39;49mextra_query, extra_body\u001b[39m=\u001b[39;49mextra_body, timeout\u001b[39m=\u001b[39;49mtimeout\n\u001b[0;32m    625\u001b[0m         ),\n\u001b[0;32m    626\u001b[0m         cast_to\u001b[39m=\u001b[39;49mChatCompletion,\n\u001b[0;32m    627\u001b[0m         stream\u001b[39m=\u001b[39;49mstream \u001b[39mor\u001b[39;49;00m \u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    628\u001b[0m         stream_cls\u001b[39m=\u001b[39;49mStream[ChatCompletionChunk],\n\u001b[0;32m    629\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\jithi\\.conda\\envs\\pytorch_OIIO\\lib\\site-packages\\openai\\_base_client.py:1055\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1041\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpost\u001b[39m(\n\u001b[0;32m   1042\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   1043\u001b[0m     path: \u001b[39mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1050\u001b[0m     stream_cls: \u001b[39mtype\u001b[39m[_StreamT] \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   1051\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ResponseT \u001b[39m|\u001b[39m _StreamT:\n\u001b[0;32m   1052\u001b[0m     opts \u001b[39m=\u001b[39m FinalRequestOptions\u001b[39m.\u001b[39mconstruct(\n\u001b[0;32m   1053\u001b[0m         method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpost\u001b[39m\u001b[39m\"\u001b[39m, url\u001b[39m=\u001b[39mpath, json_data\u001b[39m=\u001b[39mbody, files\u001b[39m=\u001b[39mto_httpx_files(files), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions\n\u001b[0;32m   1054\u001b[0m     )\n\u001b[1;32m-> 1055\u001b[0m     \u001b[39mreturn\u001b[39;00m cast(ResponseT, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest(cast_to, opts, stream\u001b[39m=\u001b[39;49mstream, stream_cls\u001b[39m=\u001b[39;49mstream_cls))\n",
      "File \u001b[1;32mc:\\Users\\jithi\\.conda\\envs\\pytorch_OIIO\\lib\\site-packages\\openai\\_base_client.py:834\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    825\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[0;32m    826\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    827\u001b[0m     cast_to: Type[ResponseT],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    832\u001b[0m     stream_cls: \u001b[39mtype\u001b[39m[_StreamT] \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    833\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ResponseT \u001b[39m|\u001b[39m _StreamT:\n\u001b[1;32m--> 834\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request(\n\u001b[0;32m    835\u001b[0m         cast_to\u001b[39m=\u001b[39;49mcast_to,\n\u001b[0;32m    836\u001b[0m         options\u001b[39m=\u001b[39;49moptions,\n\u001b[0;32m    837\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    838\u001b[0m         stream_cls\u001b[39m=\u001b[39;49mstream_cls,\n\u001b[0;32m    839\u001b[0m         remaining_retries\u001b[39m=\u001b[39;49mremaining_retries,\n\u001b[0;32m    840\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\jithi\\.conda\\envs\\pytorch_OIIO\\lib\\site-packages\\openai\\_base_client.py:865\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    863\u001b[0m \u001b[39mexcept\u001b[39;00m httpx\u001b[39m.\u001b[39mHTTPStatusError \u001b[39mas\u001b[39;00m err:  \u001b[39m# thrown on 4xx and 5xx status code\u001b[39;00m\n\u001b[0;32m    864\u001b[0m     \u001b[39mif\u001b[39;00m retries \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_retry(err\u001b[39m.\u001b[39mresponse):\n\u001b[1;32m--> 865\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_retry_request(\n\u001b[0;32m    866\u001b[0m             options,\n\u001b[0;32m    867\u001b[0m             cast_to,\n\u001b[0;32m    868\u001b[0m             retries,\n\u001b[0;32m    869\u001b[0m             err\u001b[39m.\u001b[39;49mresponse\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    870\u001b[0m             stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    871\u001b[0m             stream_cls\u001b[39m=\u001b[39;49mstream_cls,\n\u001b[0;32m    872\u001b[0m         )\n\u001b[0;32m    874\u001b[0m     \u001b[39m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[0;32m    875\u001b[0m     \u001b[39m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[0;32m    876\u001b[0m     err\u001b[39m.\u001b[39mresponse\u001b[39m.\u001b[39mread()\n",
      "File \u001b[1;32mc:\\Users\\jithi\\.conda\\envs\\pytorch_OIIO\\lib\\site-packages\\openai\\_base_client.py:925\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[1;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[0;32m    921\u001b[0m \u001b[39m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[0;32m    922\u001b[0m \u001b[39m# different thread if necessary.\u001b[39;00m\n\u001b[0;32m    923\u001b[0m time\u001b[39m.\u001b[39msleep(timeout)\n\u001b[1;32m--> 925\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request(\n\u001b[0;32m    926\u001b[0m     options\u001b[39m=\u001b[39;49moptions,\n\u001b[0;32m    927\u001b[0m     cast_to\u001b[39m=\u001b[39;49mcast_to,\n\u001b[0;32m    928\u001b[0m     remaining_retries\u001b[39m=\u001b[39;49mremaining,\n\u001b[0;32m    929\u001b[0m     stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    930\u001b[0m     stream_cls\u001b[39m=\u001b[39;49mstream_cls,\n\u001b[0;32m    931\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\jithi\\.conda\\envs\\pytorch_OIIO\\lib\\site-packages\\openai\\_base_client.py:865\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    863\u001b[0m \u001b[39mexcept\u001b[39;00m httpx\u001b[39m.\u001b[39mHTTPStatusError \u001b[39mas\u001b[39;00m err:  \u001b[39m# thrown on 4xx and 5xx status code\u001b[39;00m\n\u001b[0;32m    864\u001b[0m     \u001b[39mif\u001b[39;00m retries \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_retry(err\u001b[39m.\u001b[39mresponse):\n\u001b[1;32m--> 865\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_retry_request(\n\u001b[0;32m    866\u001b[0m             options,\n\u001b[0;32m    867\u001b[0m             cast_to,\n\u001b[0;32m    868\u001b[0m             retries,\n\u001b[0;32m    869\u001b[0m             err\u001b[39m.\u001b[39;49mresponse\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    870\u001b[0m             stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    871\u001b[0m             stream_cls\u001b[39m=\u001b[39;49mstream_cls,\n\u001b[0;32m    872\u001b[0m         )\n\u001b[0;32m    874\u001b[0m     \u001b[39m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[0;32m    875\u001b[0m     \u001b[39m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[0;32m    876\u001b[0m     err\u001b[39m.\u001b[39mresponse\u001b[39m.\u001b[39mread()\n",
      "File \u001b[1;32mc:\\Users\\jithi\\.conda\\envs\\pytorch_OIIO\\lib\\site-packages\\openai\\_base_client.py:925\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[1;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[0;32m    921\u001b[0m \u001b[39m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[0;32m    922\u001b[0m \u001b[39m# different thread if necessary.\u001b[39;00m\n\u001b[0;32m    923\u001b[0m time\u001b[39m.\u001b[39msleep(timeout)\n\u001b[1;32m--> 925\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request(\n\u001b[0;32m    926\u001b[0m     options\u001b[39m=\u001b[39;49moptions,\n\u001b[0;32m    927\u001b[0m     cast_to\u001b[39m=\u001b[39;49mcast_to,\n\u001b[0;32m    928\u001b[0m     remaining_retries\u001b[39m=\u001b[39;49mremaining,\n\u001b[0;32m    929\u001b[0m     stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    930\u001b[0m     stream_cls\u001b[39m=\u001b[39;49mstream_cls,\n\u001b[0;32m    931\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\jithi\\.conda\\envs\\pytorch_OIIO\\lib\\site-packages\\openai\\_base_client.py:877\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    874\u001b[0m     \u001b[39m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[0;32m    875\u001b[0m     \u001b[39m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[0;32m    876\u001b[0m     err\u001b[39m.\u001b[39mresponse\u001b[39m.\u001b[39mread()\n\u001b[1;32m--> 877\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_status_error_from_response(err\u001b[39m.\u001b[39mresponse) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m    878\u001b[0m \u001b[39mexcept\u001b[39;00m httpx\u001b[39m.\u001b[39mTimeoutException \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m    879\u001b[0m     \u001b[39mif\u001b[39;00m retries \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[1;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}\n",
    "\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading tokenizer_config.json: 100%|██████████| 749/749 [00:00<?, ?B/s] \n",
      "c:\\Users\\jithi\\.conda\\envs\\pytorch_OIIO\\lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\jithi\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Tokenizer class CodeLlamaTokenizer does not exist or is not currently imported.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jithi\\OneDrive\\Desktop\\VsCode\\capstone\\extra.ipynb Cell 1\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jithi/OneDrive/Desktop/VsCode/capstone/extra.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtransformers\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jithi/OneDrive/Desktop/VsCode/capstone/extra.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jithi/OneDrive/Desktop/VsCode/capstone/extra.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m tokenizer \u001b[39m=\u001b[39m AutoTokenizer\u001b[39m.\u001b[39;49mfrom_pretrained(\u001b[39m\"\u001b[39;49m\u001b[39mcodellama/CodeLlama-7b-hf\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jithi/OneDrive/Desktop/VsCode/capstone/extra.ipynb#W4sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m pipeline \u001b[39m=\u001b[39m transformers\u001b[39m.\u001b[39mpipeline(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jithi/OneDrive/Desktop/VsCode/capstone/extra.ipynb#W4sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtext-generation\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jithi/OneDrive/Desktop/VsCode/capstone/extra.ipynb#W4sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     model\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcodellama/CodeLlama-7b-hf\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jithi/OneDrive/Desktop/VsCode/capstone/extra.ipynb#W4sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     torch_dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat16,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jithi/OneDrive/Desktop/VsCode/capstone/extra.ipynb#W4sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     device_map\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jithi/OneDrive/Desktop/VsCode/capstone/extra.ipynb#W4sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\jithi\\.conda\\envs\\pytorch_OIIO\\lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:724\u001b[0m, in \u001b[0;36mAutoTokenizer.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m    722\u001b[0m         tokenizer_class \u001b[39m=\u001b[39m tokenizer_class_from_name(tokenizer_class_candidate)\n\u001b[0;32m    723\u001b[0m     \u001b[39mif\u001b[39;00m tokenizer_class \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 724\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    725\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTokenizer class \u001b[39m\u001b[39m{\u001b[39;00mtokenizer_class_candidate\u001b[39m}\u001b[39;00m\u001b[39m does not exist or is not currently imported.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    726\u001b[0m         )\n\u001b[0;32m    727\u001b[0m     \u001b[39mreturn\u001b[39;00m tokenizer_class\u001b[39m.\u001b[39mfrom_pretrained(pretrained_model_name_or_path, \u001b[39m*\u001b[39minputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    729\u001b[0m \u001b[39m# Otherwise we have to be creative.\u001b[39;00m\n\u001b[0;32m    730\u001b[0m \u001b[39m# if model is an encoder decoder, the encoder tokenizer class is used by default\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Tokenizer class CodeLlamaTokenizer does not exist or is not currently imported."
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import transformers\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"codellama/CodeLlama-7b-hf\")\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=\"codellama/CodeLlama-7b-hf\",\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import json\n",
    "import cv2\n",
    "from datetime import datetime\n",
    "\n",
    "# Initialize checkbox states\n",
    "checkbox_states = {\"person\": False, \"cat\": False, \"car\": False, \"truck\": False,\"bicycle\":False,\"motorcycle\":False,\"dog\":False}\n",
    "\n",
    "def update_checkboxes_and_process_video(person, cat, car, truck, bicycle, motorcycle, dog, video_path):\n",
    "    # Update checkbox states\n",
    "    checkbox_states[\"person\"] = person\n",
    "    checkbox_states[\"cat\"] = cat\n",
    "    checkbox_states[\"car\"] = car\n",
    "    checkbox_states[\"truck\"] = truck\n",
    "    checkbox_states[\"bicycle\"] = bicycle\n",
    "    checkbox_states[\"motorcycle\"] = motorcycle\n",
    "    checkbox_states[\"dog\"] = dog\n",
    "    checkbox_states[\"path\"] = video_path\n",
    "    # Write to JSON file\n",
    "    with open(\"checkbox_states.json\", \"w\") as f:\n",
    "        json.dump(checkbox_states, f)\n",
    "\n",
    "    # Process Video\n",
    "    if video_path:\n",
    "        process_video(video_path)  # Function to process the video, similar to your first code snippet\n",
    "\n",
    "    return f\"Updated and saved checkbox states: {checkbox_states}\"\n",
    "\n",
    "def process_video(video_path):\n",
    "    # video_path=\"C:\\\\Users\\\\jithi\\\\OneDrive\\\\Desktop\\\\VsCode\\\\capstone\\\\track.mp4\"\n",
    "    json_path = \"C:\\\\Users\\\\jithi\\\\OneDrive\\\\Desktop\\\\VsCode\\\\capstone\\\\checkbox_states.json\"\n",
    "    \n",
    "    with open(json_path, 'r') as f:\n",
    "            checkbox_states = json.load(f)\n",
    "    video_path=checkbox_states.get(\"path\")\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    csv_file = open('logs.csv', 'w', newline='')\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "    csv_writer.writerow(['Time', 'ID', 'Class'])\n",
    "\n",
    "    # Define colors for each class\n",
    "    class_colors = {\n",
    "        0: (0, 0, 255),\n",
    "        2: (0, 255, 0),\n",
    "        16: (255, 0, 0),\n",
    "        # Add more classes and their colors\n",
    "    }\n",
    "    id_to_name = {\n",
    "    0: 'person',\n",
    "    2: 'car',\n",
    "    16: 'dog'\n",
    "    # 16:'none',\n",
    "    # 7:'bird',\n",
    "    # 58:'pot',\n",
    "    # 10:'none'\n",
    "    }\n",
    "\n",
    "    thickness = 2\n",
    "    fontscale = 0.5\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        with open(json_path, 'r') as f:\n",
    "            checkbox_states = json.load(f)\n",
    "        results = model(frame)\n",
    "        df = results.pandas().xyxy[0]\n",
    "        detections = []\n",
    "\n",
    "            # Check if this class should have a bounding box drawn, according to the JSON file\n",
    "        for _, row in df.iterrows():\n",
    "            class_name = row['class']\n",
    "            class_str=id_to_name.get(class_name)\n",
    "            \n",
    "            # x1, y1, x2, y2 = int(row['xmin']), int(row['ymin']), int(row['xmax']), int(row['ymax'])\n",
    "            # class_name = row['class']\n",
    "            # detections.append([x1, y1, x2, y2, 1.0, class_name])\n",
    "                \n",
    "                \n",
    "            if checkbox_states.get(str(class_str), False):\n",
    "                x1, y1, x2, y2 = int(row['xmin']), int(row['ymin']), int(row['xmax']), int(row['ymax'])\n",
    "                class_name = row['class']\n",
    "                detections.append([x1, y1, x2, y2, 1.0, class_name])\n",
    "\n",
    "        tracks = tracker.update(np.array(detections), frame)\n",
    "\n",
    "        xyxys = tracks[:, 0:4].astype('int')\n",
    "        ids = tracks[:, 4].astype('int')\n",
    "        confs = tracks[:, 5]\n",
    "        clss = tracks[:, 6].astype('int')\n",
    "        inds = tracks[:, 7].astype('int')\n",
    "\n",
    "        if tracks.shape[0] != 0:\n",
    "            for xyxy, id, conf, cls in zip(xyxys, ids, confs, clss):\n",
    "                color = class_colors.get(cls, (0, 0, 0))  # Default color is black\n",
    "                frame = cv2.rectangle(frame, (xyxy[0], xyxy[1]), (xyxy[2], xyxy[3]), color, thickness)\n",
    "                text = f'id: {id}, class: {id_to_name.get(cls)}'\n",
    "                frame = cv2.putText(frame, text, (xyxy[0], xyxy[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, fontscale, color, thickness)\n",
    "                current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                csv_writer.writerow([current_time, id, cls])    \n",
    "\n",
    "        cv2.imshow('Video with Object IDs and Classes', frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Gradio interface setup\n",
    "demo = gr.Interface(\n",
    "    update_checkboxes_and_process_video,\n",
    "    [\n",
    "        gr.Checkbox(initial_value=checkbox_states[\"person\"], label=\"person\"),\n",
    "        gr.Checkbox(initial_value=checkbox_states[\"cat\"], label=\"cat\"),\n",
    "        gr.Checkbox(initial_value=checkbox_states[\"car\"], label=\"car\"),\n",
    "        gr.Checkbox(initial_value=checkbox_states[\"truck\"], label=\"truck\"),\n",
    "        gr.Checkbox(initial_value=checkbox_states[\"bicycle\"], label=\"bicycle\"),\n",
    "        gr.Checkbox(initial_value=checkbox_states[\"motorcycle\"], label=\"motorcycle\"),\n",
    "        gr.Checkbox(initial_value=checkbox_states[\"dog\"], label=\"dog\"),\n",
    "        gr.Textbox(label=\"Video Path\"),\n",
    "    ],\n",
    "    \"text\"\n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# without calculated time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jithi\\.conda\\envs\\pytorch_OIIO\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import json\n",
    "import cv2\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "id_to_name = {\n",
    "    0: 'person',\n",
    "    2: 'car',\n",
    "    16: 'dog'\n",
    "    # 16:'none',\n",
    "    # 7:'bird',\n",
    "    # 58:'pot',\n",
    "    # 10:'none'\n",
    "    }\n",
    "\n",
    "\n",
    "# Initialize checkbox states\n",
    "checkbox_states = {\"person\": False, \"cat\": False, \"car\": False, \"truck\": False,\"bicycle\":False,\"motorcycle\":False,\"dog\":False}\n",
    "\n",
    "def create_entry_exit_logs():\n",
    "    file_path = \"C:\\\\Users\\\\jithi\\\\OneDrive\\\\Desktop\\\\VsCode\\\\capstone\\\\logs.csv\"\n",
    "\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Convert the 'Time' column to datetime format for accurate processing\n",
    "    df['Time'] = pd.to_datetime(df['Time']).dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    # Group by ID and get the first and last time for each ID\n",
    "    result_df = df.groupby('ID').agg(\n",
    "        Class=('Class', 'first'),\n",
    "        Entry_Time=('Time', 'first'),\n",
    "        Exit_Time=('Time', 'last')\n",
    "    ).reset_index()    \n",
    "    result_df['Class'] = result_df['Class'].map(id_to_name)\n",
    "\n",
    "    return result_df\n",
    "\n",
    "def update_checkboxes_and_process_video(person, cat, car, truck, bicycle, motorcycle, dog, video_path):\n",
    "    # Update checkbox states\n",
    "    checkbox_states[\"person\"] = person\n",
    "    checkbox_states[\"cat\"] = cat\n",
    "    checkbox_states[\"car\"] = car\n",
    "    checkbox_states[\"truck\"] = truck\n",
    "    checkbox_states[\"bicycle\"] = bicycle\n",
    "    checkbox_states[\"motorcycle\"] = motorcycle\n",
    "    checkbox_states[\"dog\"] = dog\n",
    "    checkbox_states[\"path\"] = video_path\n",
    "    # Write to JSON file\n",
    "    with open(\"checkbox_states.json\", \"w\") as f:\n",
    "        json.dump(checkbox_states, f)\n",
    "\n",
    "    # Process Video\n",
    "    if video_path:\n",
    "        process_video(video_path)  # Function to process the video, similar to your first code snippet\n",
    "\n",
    "    return f\"Updated and saved checkbox states: {checkbox_states}\"\n",
    "\n",
    "def process_video(video_path):\n",
    "    # video_path=\"C:\\\\Users\\\\jithi\\\\OneDrive\\\\Desktop\\\\VsCode\\\\capstone\\\\track.mp4\"\n",
    "    json_path = \"C:\\\\Users\\\\jithi\\\\OneDrive\\\\Desktop\\\\VsCode\\\\capstone\\\\checkbox_states.json\"\n",
    "    \n",
    "    with open(json_path, 'r') as f:\n",
    "            checkbox_states = json.load(f)\n",
    "    video_path=checkbox_states.get(\"path\")\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    csv_file = open('logs.csv', 'w', newline='')\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "    csv_writer.writerow(['Time', 'ID', 'Class'])\n",
    "\n",
    "    # Define colors for each class\n",
    "    class_colors = {\n",
    "        0: (0, 0, 255),\n",
    "        2: (0, 255, 0),\n",
    "        16: (255, 0, 0),\n",
    "        # Add more classes and their colors\n",
    "    }\n",
    "    # id_to_name = {\n",
    "    # 0: 'person',\n",
    "    # 2: 'car',\n",
    "    # 16: 'dog'\n",
    "    # # 16:'none',\n",
    "    # # 7:'bird',\n",
    "    # # 58:'pot',\n",
    "    # # 10:'none'\n",
    "    # }\n",
    "\n",
    "    thickness = 2\n",
    "    fontscale = 0.5\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        with open(json_path, 'r') as f:\n",
    "            checkbox_states = json.load(f)\n",
    "        results = model(frame)\n",
    "        df = results.pandas().xyxy[0]\n",
    "        detections = []\n",
    "\n",
    "            # Check if this class should have a bounding box drawn, according to the JSON file\n",
    "        for _, row in df.iterrows():\n",
    "            class_name = row['class']\n",
    "            class_str=id_to_name.get(class_name)\n",
    "\n",
    "            if checkbox_states.get(str(class_str), False):\n",
    "                x1, y1, x2, y2 = int(row['xmin']), int(row['ymin']), int(row['xmax']), int(row['ymax'])\n",
    "                class_name = row['class']\n",
    "                detections.append([x1, y1, x2, y2, 1.0, class_name])\n",
    "\n",
    "        tracks = tracker.update(np.array(detections), frame)\n",
    "\n",
    "        xyxys = tracks[:, 0:4].astype('int')\n",
    "        ids = tracks[:, 4].astype('int')\n",
    "        confs = tracks[:, 5]\n",
    "        clss = tracks[:, 6].astype('int')\n",
    "        inds = tracks[:, 7].astype('int')\n",
    "\n",
    "        if tracks.shape[0] != 0:\n",
    "            for xyxy, id, conf, cls in zip(xyxys, ids, confs, clss):\n",
    "                color = class_colors.get(cls, (0, 0, 0))  # Default color is black\n",
    "                frame = cv2.rectangle(frame, (xyxy[0], xyxy[1]), (xyxy[2], xyxy[3]), color, thickness)\n",
    "                text = f'id: {id}, class: {id_to_name.get(cls)}'\n",
    "                frame = cv2.putText(frame, text, (xyxy[0], xyxy[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, fontscale, color, thickness)\n",
    "                current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                csv_writer.writerow([current_time, id, cls])    \n",
    "\n",
    "        cv2.imshow('Video with Object IDs and Classes', frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"<h1 style='font-size: 40px;'>SentinelGuard</h1>\")\n",
    "    with gr.Tabs():\n",
    "        with gr.TabItem(\"Parameters\"):\n",
    "            with gr.Row():\n",
    "                checkbox_person = gr.Checkbox(label=\"person\", value=checkbox_states[\"person\"])\n",
    "                checkbox_cat = gr.Checkbox(label=\"cat\", value=checkbox_states[\"cat\"])\n",
    "                checkbox_car = gr.Checkbox(label=\"car\", value=checkbox_states[\"car\"])\n",
    "                checkbox_truck = gr.Checkbox(label=\"truck\", value=checkbox_states[\"truck\"])\n",
    "                checkbox_bicycle = gr.Checkbox(label=\"bicycle\", value=checkbox_states[\"bicycle\"])\n",
    "                checkbox_motorcycle = gr.Checkbox(label=\"motorcycle\", value=checkbox_states[\"motorcycle\"])\n",
    "                checkbox_dog = gr.Checkbox(label=\"dog\", value=checkbox_states[\"dog\"])\n",
    "            video_path_input = gr.Textbox(label=\"Video Path\")\n",
    "            submit_button = gr.Button(\"Submit\")\n",
    "            submit_button.click(\n",
    "                update_checkboxes_and_process_video, \n",
    "                inputs=[checkbox_person, checkbox_cat, checkbox_car, checkbox_truck, checkbox_bicycle, checkbox_motorcycle, checkbox_dog, video_path_input], \n",
    "                outputs=[]\n",
    "            )\n",
    "        with gr.TabItem(\"Logs\"):\n",
    "            create_logs_button = gr.Button(\"Create Entry/Exit time logs\")\n",
    "            logs_output = gr.Dataframe()\n",
    "            create_logs_button.click(\n",
    "                create_entry_exit_logs,\n",
    "                outputs=logs_output\n",
    "            )\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_OIIO",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
